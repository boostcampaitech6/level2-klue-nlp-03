import streamlit as st
import torch
import transformers
from load_data import load_demo_data, RE_Dataset
from inference import inference_demo, num_to_label, tokenize_test_dataset
from transformers import AutoTokenizer
from model import Model
import argparse
# from train import num_to_label

def model_setup():
    print('model setup')
    Tokenizer_NAME = "team-lucid/deberta-v3-base-korean"
    tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)

    ## load my model
    MODEL_NAME = './best_model' # model dir.
    model = Model(MODEL_NAME, num_labels=30)
    model.parameters

    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.eval()
    return model, tokenizer, device

def main():
    """RE(ê´€ê³„ ì¶”ì¶œ) Project -Team ë™í–‰-"""
    st.markdown("<h2 style='text-align: center; color: red;'>Relation Extraction ğŸ¦†</h2>", unsafe_allow_html=True)

    st.session_state.re = None
    st.text_input('ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”', key='sentence')
    st.text_input('ë‹¨ì–´ 1 ì„ ì…ë ¥í•˜ì„¸ìš”', key='subject_entity')
    st.text_input('ë‹¨ì–´ 2 ì„ ì…ë ¥í•˜ì„¸ìš”', key='object_entity')

    def fill_all_inputs():
        if not st.session_state.sentence or not st.session_state.subject_entity or not st.session_state.object_entity:
            return False
        return True
    
    if st.button('ê´€ê³„ ì¶”ì¶œ'):
        if not fill_all_inputs():
            st.warning('ëª¨ë“  ë¹ˆì¹¸ì„ ì±„ì›Œì£¼ì„¸ìš”')
        else:
            sentence = st.session_state.sentence
            subject_entity = st.session_state.subject_entity
            object_entity = st.session_state.object_entity

            demo_dataset = load_demo_data(sentence, subject_entity, object_entity)
            test_id, test_dataset, test_label = tokenize_test_dataset(demo_dataset, tokenizer)
            Re_test_dataset = RE_Dataset(test_dataset ,test_label)

            pred_answer, output_prob = inference_demo(model, Re_test_dataset, device)
            answer = str(num_to_label(pred_answer)[0])
            answers = answer.split(':')
            st.session_state.re = answers

    if st.session_state.re is not None:
        if len(answers) == 1:
            st.write('ê´€ê³„ ì¶”ì¶œ ê²°ê³¼ : ', st.session_state.re[0])
        else:
            st.write('ë‘ ë‹¨ì–´ ê°„ ê´€ê³„ : ', st.session_state.re[0] + '-' + st.session_state.re[1])


if __name__ == "__main__" :
    if 'model' not in st.session_state:
        st.session_state.model, st.session_state.tokenizer, st.session_state.device = model_setup()
    model = st.session_state.model
    tokenizer = st.session_state.tokenizer
    device = st.session_state.device
    
    main()