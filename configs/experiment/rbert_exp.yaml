# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: rbert_data
  - override /model: rbert_model
  - override /trainer: default
  - override /paths: rbert_paths
  - override /hydra: rbert_hydra

#   # Inference하실 때 주석처리 해주세요 ###########################
#   - override /callbacks: default
# callbacks:
#   early_stopping:
#     patience: 5

# Inference하실 때 주석처리 해제해주세요 ###########################
# ckpt_path: ${paths.log_dir}train/runs/${model.model_name}/checkpoints/best_model.ckpt

# --------------------------------------------------------------------------------------------

# 실험마다 우리 바꿔줄 것
# train과 inference 단계에서 동일하게 사용 가능합니다.

tags: ["김진기", "xlm-roberta-large", "RBERT"] # 실험마다 꼭 작성 부탁드려요

seed: 777

test: True # Test 진행 여부. 'True'이면 train, validation 외에 추가적으로 test를 진행합니다.

trainer:
  min_epochs: 20
  max_epochs: 200
  gradient_clip_val: 1.
  # accumulate_grad_batches: 1

model:
  model_name: "xlm-roberta-large"
  dropout_rate: 0.2

  optimizer:
    lr: 3e-5
    eps: 1e-6

data: # 'data/' 디렉토리에 있는 데이터 입니다.
  file_train: train.csv
  file_val: dev.csv
  file_test: test.csv
  batch_size: 64

logger:
  wandb:
    tags: ${tags}
    group: "klue-re"
  aim:
    experiment: "klue"
